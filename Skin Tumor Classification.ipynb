{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skin Tumor Classification using Image and Tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage\n",
    "from skimage import io,transform\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "The dataset is a combination of skin tumor image data and the sex and (grouped) age. Some sex and age records are missing (noted as \"unknown\"). The meta-data looks like the following as a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>age_approximate</th>\n",
       "      <th>sex</th>\n",
       "      <th>class</th>\n",
       "      <th>melanoma</th>\n",
       "      <th>seborrheic_keratosis</th>\n",
       "      <th>nevus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>ISIC_0014062.jpg</td>\n",
       "      <td>60</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>ISIC_0014253.jpg</td>\n",
       "      <td>60</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>ISIC_0011382.jpg</td>\n",
       "      <td>85</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>ISIC_0006711.jpg</td>\n",
       "      <td>15</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>ISIC_0006940.jpg</td>\n",
       "      <td>15</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>ISIC_0002469.jpg</td>\n",
       "      <td>15</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>ISIC_0012386.jpg</td>\n",
       "      <td>85</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>ISIC_0011402.jpg</td>\n",
       "      <td>20</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>ISIC_0014169.jpg</td>\n",
       "      <td>85</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>ISIC_0000525.jpg</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              image_id age_approximate      sex  class  melanoma  \\\n",
       "1684  ISIC_0014062.jpg              60   female      0         1   \n",
       "1740  ISIC_0014253.jpg              60   female      2         0   \n",
       "1043  ISIC_0011382.jpg              85     male      2         0   \n",
       "533   ISIC_0006711.jpg              15     male      2         0   \n",
       "537   ISIC_0006940.jpg              15     male      2         0   \n",
       "487   ISIC_0002469.jpg              15   female      2         0   \n",
       "1149  ISIC_0012386.jpg              85     male      1         0   \n",
       "1050  ISIC_0011402.jpg              20     male      2         0   \n",
       "1720  ISIC_0014169.jpg              85     male      1         0   \n",
       "427   ISIC_0000525.jpg         unknown  unknown      2         0   \n",
       "\n",
       "      seborrheic_keratosis  nevus  \n",
       "1684                     0      0  \n",
       "1740                     0      1  \n",
       "1043                     0      1  \n",
       "533                      0      1  \n",
       "537                      0      1  \n",
       "487                      0      1  \n",
       "1149                     1      0  \n",
       "1050                     0      1  \n",
       "1720                     1      0  \n",
       "427                      0      1  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data/ISIC-2017_Training_Data_metadata.csv').sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define the dataset for training and validation below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_lesion(Dataset):\n",
    "    def __init__(self,csv_file,img_dir,transform=True,dropna=True):\n",
    "        self.csv_file = csv_file\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.dropna = dropna\n",
    "        if self.dropna:\n",
    "            missing_values =['unknown','']\n",
    "            self.meta_data = pd.read_csv(csv_file,na_values=missing_values).dropna()\n",
    "            self.meta_data['sex']= pd.get_dummies(self.meta_data['sex'])\n",
    "        else:\n",
    "            self.meta_data = pd.read_csv(csv_file)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.meta_data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        img_path = os.path.join(self.img_dir,self.meta_data.iloc[idx,0])\n",
    "        img = io.imread(img_path)\n",
    "        if self.transform:\n",
    "            img = transform.resize(img,(224,224))\n",
    "            transform_tensor = transforms.Compose([transforms.ToTensor(),\n",
    "                                                  transforms.RandomRotation(30),\n",
    "                                                  transforms.RandomVerticalFlip(),\n",
    "                                                  transforms.RandomHorizontalFlip()])\n",
    "            img = transform_tensor(img)\n",
    "        \n",
    "        target = torch.from_numpy(np.array(self.meta_data.iloc[idx,3]).astype(float))\n",
    "        \n",
    "        if self.dropna:\n",
    "            tab_data = torch.from_numpy(np.array(self.meta_data.iloc[idx,1:3]).astype(float))\n",
    "            sample = {'image':img,'tab_data':tab_data,'target':target}\n",
    "        else:\n",
    "            sample = {'image':img,'target':target}\n",
    "                \n",
    "        return sample        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points: 2000; Image size: torch.Size([3, 224, 224]); sample target: 2.0;\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset_lesion(csv_file='data/ISIC-2017_Training_Data_metadata.csv',\n",
    "                         img_dir='data/ISIC-2017_Training_Data',dropna=False)\n",
    "rand1 = np.random.randint(len(dataset))\n",
    "sample_image,sample_target =dataset[rand1]['image'],dataset[rand1]['target']\n",
    "print(f'Number of data points: {len(dataset)}; Image size: {sample_image.shape}; sample target: {sample_target};')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training/validation data split is 80%/20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_data = int(len(dataset)*0.8)\n",
    "train_data,valid_data=torch.utils.data.random_split(dataset, [num_train_data,len(dataset)-num_train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(train_data,shuffle=True,batch_size=20)\n",
    "valid_loader=DataLoader(valid_data,shuffle=False,batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 3, 224, 224])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "di=iter(train_loader)\n",
    "di.next()['image'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataset with both image and tabular data (sex and age group) below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2 = dataset_lesion(csv_file='data/ISIC-2017_Training_Data_metadata.csv'\n",
    "                                 ,img_dir='data/ISIC-2017_Training_Data')\n",
    "num_train_data_2 = int(len(dataset_2)*0.8)\n",
    "train_data_2,valid_data_2=torch.utils.data.random_split(dataset_2, [num_train_data_2,len(dataset_2)-num_train_data_2])\n",
    "\n",
    "train_loader_2=DataLoader(train_data_2,shuffle=True,batch_size=20)\n",
    "valid_loader_2=DataLoader(valid_data_2,shuffle=False,batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 3, 224, 224])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "di_2=iter(train_loader_2)\n",
    "di_2.next()['image'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "A transfer learning approach is taken by using pre-trained model ResNet_50 replacing the final fully connected layer with customized fully connected layer with three outputs. The loss function is defined as multi-class cross-entropy loss with logits and Adam as the optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True if torch.cuda.is_available() else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "weight_class_loss = torch.tensor([0.45,0.35,0.2])\n",
    "model = torchvision.models.resnet50(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad=False\n",
    "\n",
    "model.fc=torch.nn.Linear(in_features=2048, out_features=3,bias=True)\n",
    "\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "    weight_class_loss=weight_class_loss.cuda()\n",
    "    \n",
    "criterion = torch.nn.CrossEntropyLoss(weight=weight_class_loss)\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max',factor = 0.25,patience=0,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross-entropy loss is weighted higher to the first and second class because their accuracy is lower but more important to detect correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following creates a customized model combining the pre-trained Resnet_50 for image data and a couple of fully connected layers for tabular data (sex and age group). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_img_tab(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(model_img_tab, self).__init__()\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "        self.fc1 = torch.nn.Linear(2,64)\n",
    "        self.fc2 = torch.nn.Linear(64,16)\n",
    "        # image features of 2048 + 16 tabular features \n",
    "        self.fc3 = torch.nn.Linear(2064, 3,bias=True)\n",
    "        \n",
    "        resnet50 = torchvision.models.resnet50(pretrained=True)\n",
    "        self.img_cnn = torch.nn.Sequential(*list(resnet50.children())[:-1])\n",
    "        for param in self.img_cnn.parameters():\n",
    "            param.requires_grad=False\n",
    "                \n",
    "    def forward(self,img,tab):\n",
    "        tab = self.tanh(self.fc1(tab))\n",
    "        tab = self.fc2(tab)\n",
    "        img = torch.squeeze(self.img_cnn(img))\n",
    "        out = self.fc3(torch.cat((img,tab),dim=1))        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_img_tab = model_img_tab()\n",
    "weight_class_loss = torch.tensor([0.45,0.35,0.2])\n",
    "\n",
    "if use_cuda:\n",
    "    model_img_tab.cuda() \n",
    "    weight_class_loss=weight_class_loss.cuda()\n",
    "    \n",
    "criterion_img_tab = torch.nn.CrossEntropyLoss(weight=weight_class_loss)\n",
    "optimizer_img_tab = torch.optim.Adam(model_img_tab.parameters(), lr=0.001)\n",
    "scheduler_img_tab = ReduceLROnPlateau(optimizer_img_tab, mode='max',factor = 0.1,patience=0,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation\n",
    "The training function for image only model is defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs, train_loader,valid_loader, model, optimizer,scheduler, criterion, use_cuda, save_path):\n",
    "    for e in range(1,n_epochs+1):\n",
    "        train_loss = 0\n",
    "        valid_loss = 0\n",
    "        valid_loss_min = np.Inf\n",
    "        \n",
    "        model.train()\n",
    "        for i, data in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            img = data['image'].float()\n",
    "            #tab_data = data['tab_data'][:,age0_sex1].float()\n",
    "            target = data['target'].long()\n",
    "            if use_cuda:\n",
    "                img,target = img.cuda(),target.cuda()\n",
    "\n",
    "            pred = torch.squeeze(model(img))\n",
    "            loss = criterion(pred,target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss = train_loss + ((1 / (i + 1)) * (loss.item() - train_loss))\n",
    "\n",
    "            if i % 10 == 9:    # print training loss every specified number of mini-batches\n",
    "                print('Epoch %d, Batch %d training loss: %.6f' % (e, i + 1, train_loss))\n",
    "\n",
    "        model.eval()\n",
    "        for i, data in enumerate(valid_loader):\n",
    "            img = data['image'].float()\n",
    "            #tab_data = data['tab_data'][:,age0_sex1].float()\n",
    "            target = data['target'].long()\n",
    "            if use_cuda:\n",
    "                img,target = img.cuda(),target.cuda()\n",
    "\n",
    "            pred = torch.squeeze(model(img))\n",
    "            loss = criterion(pred,target)\n",
    "            valid_loss = valid_loss + ((1 / (i + 1)) * (loss.item() - valid_loss))\n",
    "\n",
    "            # print training/validation statistics \n",
    "        print('Epoch {}: Validation Loss: {:.6f}'.format(e,valid_loss))\n",
    "        scheduler.step(valid_loss)\n",
    "\n",
    "        if valid_loss < valid_loss_min:\n",
    "            valid_loss_min = valid_loss\n",
    "            torch.save(model.state_dict(),save_path)\n",
    "        \n",
    "    return model    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image and tabular data combined model is defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_img_tab(n_epochs, train_loader,valid_loader, model, optimizer,scheduler, criterion, use_cuda, save_path):\n",
    "    for e in range(1,n_epochs+1):\n",
    "        train_loss = 0\n",
    "        valid_loss = 0\n",
    "        valid_loss_min = np.Inf\n",
    "        \n",
    "        model.train()\n",
    "        for i, data in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            img = data['image'].float()\n",
    "            tab = data['tab_data'].float()\n",
    "            target = data['target'].long()\n",
    "            if use_cuda:\n",
    "                img,tab,target = img.cuda(),tab.cuda(),target.cuda()\n",
    "\n",
    "            pred = torch.squeeze(model(img,tab))\n",
    "            loss = criterion(pred,target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss = train_loss + ((1 / (i + 1)) * (loss.item() - train_loss))\n",
    "\n",
    "            if i % 10 == 9:    # print training loss every specified number of mini-batches\n",
    "                print('Epoch %d, Batch %d training loss: %.6f' % (e, i + 1, train_loss))\n",
    "\n",
    "        model.eval()\n",
    "        for i, data in enumerate(valid_loader):\n",
    "            img = data['image'].float()\n",
    "            tab = data['tab_data'].float()\n",
    "            target = data['target'].long()\n",
    "            if use_cuda:\n",
    "                img,tab,target = img.cuda(),tab.cuda(),target.cuda()\n",
    "\n",
    "            output = torch.squeeze(model(img,tab))\n",
    "            loss = criterion(output,target)\n",
    "            valid_loss = valid_loss + ((1 / (i + 1)) * (loss.item() - valid_loss))\n",
    "            \n",
    "            # print training/validation statistics \n",
    "        print('Epoch {}: Validation Loss: {:.6f}'.format(e,valid_loss))\n",
    "        scheduler.step(valid_loss)\n",
    "\n",
    "        if valid_loss < valid_loss_min:\n",
    "            valid_loss_min = valid_loss\n",
    "            torch.save(model.state_dict(),save_path)\n",
    "        \n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following shows the training progress with 30 epochs for the image only model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 10 training loss: 1.234344\n",
      "Epoch 1, Batch 20 training loss: 1.175181\n",
      "Epoch 1, Batch 30 training loss: 1.092892\n",
      "Epoch 1, Batch 40 training loss: 1.040149\n",
      "Epoch 1, Batch 50 training loss: 1.014026\n",
      "Epoch 1, Batch 60 training loss: 0.995923\n",
      "Epoch 1, Batch 70 training loss: 0.972791\n",
      "Epoch 1, Batch 80 training loss: 0.959124\n",
      "Epoch 1: Validation Loss: 0.899880\n",
      "Epoch 2, Batch 10 training loss: 0.978761\n",
      "Epoch 2, Batch 20 training loss: 0.907497\n",
      "Epoch 2, Batch 30 training loss: 0.932743\n",
      "Epoch 2, Batch 40 training loss: 0.911808\n",
      "Epoch 2, Batch 50 training loss: 0.908966\n",
      "Epoch 2, Batch 60 training loss: 0.892483\n",
      "Epoch 2, Batch 70 training loss: 0.875453\n",
      "Epoch 2, Batch 80 training loss: 0.871224\n",
      "Epoch 2: Validation Loss: 0.805278\n",
      "Epoch     2: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 3, Batch 10 training loss: 0.825322\n",
      "Epoch 3, Batch 20 training loss: 0.795031\n",
      "Epoch 3, Batch 30 training loss: 0.761040\n",
      "Epoch 3, Batch 40 training loss: 0.761382\n",
      "Epoch 3, Batch 50 training loss: 0.762564\n",
      "Epoch 3, Batch 60 training loss: 0.763832\n",
      "Epoch 3, Batch 70 training loss: 0.763363\n",
      "Epoch 3, Batch 80 training loss: 0.765722\n",
      "Epoch 3: Validation Loss: 0.767033\n",
      "Epoch     3: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch 4, Batch 10 training loss: 0.800044\n",
      "Epoch 4, Batch 20 training loss: 0.745695\n",
      "Epoch 4, Batch 30 training loss: 0.748600\n",
      "Epoch 4, Batch 40 training loss: 0.761940\n",
      "Epoch 4, Batch 50 training loss: 0.747495\n",
      "Epoch 4, Batch 60 training loss: 0.745105\n",
      "Epoch 4, Batch 70 training loss: 0.736935\n",
      "Epoch 4, Batch 80 training loss: 0.743323\n",
      "Epoch 4: Validation Loss: 0.764917\n",
      "Epoch     4: reducing learning rate of group 0 to 1.5625e-05.\n",
      "Epoch 5, Batch 10 training loss: 0.734643\n",
      "Epoch 5, Batch 20 training loss: 0.732472\n",
      "Epoch 5, Batch 30 training loss: 0.739811\n",
      "Epoch 5, Batch 40 training loss: 0.737022\n",
      "Epoch 5, Batch 50 training loss: 0.743951\n",
      "Epoch 5, Batch 60 training loss: 0.744708\n",
      "Epoch 5, Batch 70 training loss: 0.738615\n",
      "Epoch 5, Batch 80 training loss: 0.735305\n",
      "Epoch 5: Validation Loss: 0.764128\n",
      "Epoch     5: reducing learning rate of group 0 to 3.9063e-06.\n",
      "Epoch 6, Batch 10 training loss: 0.730907\n",
      "Epoch 6, Batch 20 training loss: 0.755674\n",
      "Epoch 6, Batch 30 training loss: 0.748819\n",
      "Epoch 6, Batch 40 training loss: 0.742038\n",
      "Epoch 6, Batch 50 training loss: 0.756440\n",
      "Epoch 6, Batch 60 training loss: 0.755332\n",
      "Epoch 6, Batch 70 training loss: 0.753369\n",
      "Epoch 6, Batch 80 training loss: 0.747719\n",
      "Epoch 6: Validation Loss: 0.755214\n",
      "Epoch     6: reducing learning rate of group 0 to 9.7656e-07.\n",
      "Epoch 7, Batch 10 training loss: 0.760868\n",
      "Epoch 7, Batch 20 training loss: 0.752727\n",
      "Epoch 7, Batch 30 training loss: 0.752388\n",
      "Epoch 7, Batch 40 training loss: 0.730798\n",
      "Epoch 7, Batch 50 training loss: 0.732961\n",
      "Epoch 7, Batch 60 training loss: 0.728360\n",
      "Epoch 7, Batch 70 training loss: 0.730769\n",
      "Epoch 7, Batch 80 training loss: 0.738194\n",
      "Epoch 7: Validation Loss: 0.756639\n",
      "Epoch     7: reducing learning rate of group 0 to 2.4414e-07.\n",
      "Epoch 8, Batch 10 training loss: 0.750327\n",
      "Epoch 8, Batch 20 training loss: 0.740711\n",
      "Epoch 8, Batch 30 training loss: 0.752313\n",
      "Epoch 8, Batch 40 training loss: 0.753370\n",
      "Epoch 8, Batch 50 training loss: 0.737918\n",
      "Epoch 8, Batch 60 training loss: 0.740432\n",
      "Epoch 8, Batch 70 training loss: 0.743299\n",
      "Epoch 8, Batch 80 training loss: 0.747408\n",
      "Epoch 8: Validation Loss: 0.763594\n",
      "Epoch     8: reducing learning rate of group 0 to 6.1035e-08.\n",
      "Epoch 9, Batch 10 training loss: 0.716014\n",
      "Epoch 9, Batch 20 training loss: 0.709698\n",
      "Epoch 9, Batch 30 training loss: 0.713717\n",
      "Epoch 9, Batch 40 training loss: 0.725192\n",
      "Epoch 9, Batch 50 training loss: 0.730768\n",
      "Epoch 9, Batch 60 training loss: 0.720391\n",
      "Epoch 9, Batch 70 training loss: 0.722798\n",
      "Epoch 9, Batch 80 training loss: 0.737881\n",
      "Epoch 9: Validation Loss: 0.769603\n",
      "Epoch     9: reducing learning rate of group 0 to 1.5259e-08.\n",
      "Epoch 10, Batch 10 training loss: 0.713637\n",
      "Epoch 10, Batch 20 training loss: 0.723347\n",
      "Epoch 10, Batch 30 training loss: 0.745645\n",
      "Epoch 10, Batch 40 training loss: 0.745584\n",
      "Epoch 10, Batch 50 training loss: 0.741694\n",
      "Epoch 10, Batch 60 training loss: 0.734926\n",
      "Epoch 10, Batch 70 training loss: 0.739326\n",
      "Epoch 10, Batch 80 training loss: 0.748034\n",
      "Epoch 10: Validation Loss: 0.736911\n",
      "Epoch    10: reducing learning rate of group 0 to 3.8147e-09.\n",
      "Epoch 11, Batch 10 training loss: 0.782028\n",
      "Epoch 11, Batch 20 training loss: 0.773591\n",
      "Epoch 11, Batch 30 training loss: 0.758068\n",
      "Epoch 11, Batch 40 training loss: 0.754869\n",
      "Epoch 11, Batch 50 training loss: 0.748681\n",
      "Epoch 11, Batch 60 training loss: 0.734593\n",
      "Epoch 11, Batch 70 training loss: 0.730214\n",
      "Epoch 11, Batch 80 training loss: 0.733162\n",
      "Epoch 11: Validation Loss: 0.764558\n",
      "Epoch 12, Batch 10 training loss: 0.759724\n",
      "Epoch 12, Batch 20 training loss: 0.746695\n",
      "Epoch 12, Batch 30 training loss: 0.742275\n",
      "Epoch 12, Batch 40 training loss: 0.727220\n",
      "Epoch 12, Batch 50 training loss: 0.727987\n",
      "Epoch 12, Batch 60 training loss: 0.725997\n",
      "Epoch 12, Batch 70 training loss: 0.730316\n",
      "Epoch 12, Batch 80 training loss: 0.728679\n",
      "Epoch 12: Validation Loss: 0.762403\n",
      "Epoch 13, Batch 10 training loss: 0.768557\n",
      "Epoch 13, Batch 20 training loss: 0.774871\n",
      "Epoch 13, Batch 30 training loss: 0.753379\n",
      "Epoch 13, Batch 40 training loss: 0.735133\n",
      "Epoch 13, Batch 50 training loss: 0.754093\n",
      "Epoch 13, Batch 60 training loss: 0.753879\n",
      "Epoch 13, Batch 70 training loss: 0.746662\n",
      "Epoch 13, Batch 80 training loss: 0.750087\n",
      "Epoch 13: Validation Loss: 0.760968\n",
      "Epoch 14, Batch 10 training loss: 0.699706\n",
      "Epoch 14, Batch 20 training loss: 0.689666\n",
      "Epoch 14, Batch 30 training loss: 0.707573\n",
      "Epoch 14, Batch 40 training loss: 0.715211\n",
      "Epoch 14, Batch 50 training loss: 0.715999\n",
      "Epoch 14, Batch 60 training loss: 0.727401\n",
      "Epoch 14, Batch 70 training loss: 0.741570\n",
      "Epoch 14, Batch 80 training loss: 0.740113\n",
      "Epoch 14: Validation Loss: 0.784123\n",
      "Epoch 15, Batch 10 training loss: 0.799220\n",
      "Epoch 15, Batch 20 training loss: 0.750967\n",
      "Epoch 15, Batch 30 training loss: 0.739888\n",
      "Epoch 15, Batch 40 training loss: 0.753973\n",
      "Epoch 15, Batch 50 training loss: 0.753707\n",
      "Epoch 15, Batch 60 training loss: 0.748690\n",
      "Epoch 15, Batch 70 training loss: 0.751270\n",
      "Epoch 15, Batch 80 training loss: 0.746268\n",
      "Epoch 15: Validation Loss: 0.756628\n",
      "Epoch 16, Batch 10 training loss: 0.771922\n",
      "Epoch 16, Batch 20 training loss: 0.716734\n",
      "Epoch 16, Batch 30 training loss: 0.738373\n",
      "Epoch 16, Batch 40 training loss: 0.746709\n",
      "Epoch 16, Batch 50 training loss: 0.747653\n",
      "Epoch 16, Batch 60 training loss: 0.747522\n",
      "Epoch 16, Batch 70 training loss: 0.738441\n",
      "Epoch 16, Batch 80 training loss: 0.737530\n",
      "Epoch 16: Validation Loss: 0.771963\n",
      "Epoch 17, Batch 10 training loss: 0.683064\n",
      "Epoch 17, Batch 20 training loss: 0.697223\n",
      "Epoch 17, Batch 30 training loss: 0.717384\n",
      "Epoch 17, Batch 40 training loss: 0.731366\n",
      "Epoch 17, Batch 50 training loss: 0.719416\n",
      "Epoch 17, Batch 60 training loss: 0.733575\n",
      "Epoch 17, Batch 70 training loss: 0.743879\n",
      "Epoch 17, Batch 80 training loss: 0.734963\n",
      "Epoch 17: Validation Loss: 0.754819\n",
      "Epoch 18, Batch 10 training loss: 0.715343\n",
      "Epoch 18, Batch 20 training loss: 0.716484\n",
      "Epoch 18, Batch 30 training loss: 0.734878\n",
      "Epoch 18, Batch 40 training loss: 0.726427\n",
      "Epoch 18, Batch 50 training loss: 0.738048\n",
      "Epoch 18, Batch 60 training loss: 0.738322\n",
      "Epoch 18, Batch 70 training loss: 0.745410\n",
      "Epoch 18, Batch 80 training loss: 0.748480\n",
      "Epoch 18: Validation Loss: 0.763966\n",
      "Epoch 19, Batch 10 training loss: 0.722451\n",
      "Epoch 19, Batch 20 training loss: 0.712264\n",
      "Epoch 19, Batch 30 training loss: 0.713020\n",
      "Epoch 19, Batch 40 training loss: 0.714249\n",
      "Epoch 19, Batch 50 training loss: 0.726483\n",
      "Epoch 19, Batch 60 training loss: 0.730249\n",
      "Epoch 19, Batch 70 training loss: 0.726158\n",
      "Epoch 19, Batch 80 training loss: 0.728343\n",
      "Epoch 19: Validation Loss: 0.776625\n",
      "Epoch 20, Batch 10 training loss: 0.805498\n",
      "Epoch 20, Batch 20 training loss: 0.745474\n",
      "Epoch 20, Batch 30 training loss: 0.743310\n",
      "Epoch 20, Batch 40 training loss: 0.737745\n",
      "Epoch 20, Batch 50 training loss: 0.732521\n",
      "Epoch 20, Batch 60 training loss: 0.737994\n",
      "Epoch 20, Batch 70 training loss: 0.731313\n",
      "Epoch 20, Batch 80 training loss: 0.733051\n",
      "Epoch 20: Validation Loss: 0.761418\n",
      "Epoch 21, Batch 10 training loss: 0.805085\n",
      "Epoch 21, Batch 20 training loss: 0.770144\n",
      "Epoch 21, Batch 30 training loss: 0.758445\n",
      "Epoch 21, Batch 40 training loss: 0.743575\n",
      "Epoch 21, Batch 50 training loss: 0.738444\n",
      "Epoch 21, Batch 60 training loss: 0.728388\n",
      "Epoch 21, Batch 70 training loss: 0.743926\n",
      "Epoch 21, Batch 80 training loss: 0.743207\n",
      "Epoch 21: Validation Loss: 0.773609\n",
      "Epoch 22, Batch 10 training loss: 0.722821\n",
      "Epoch 22, Batch 20 training loss: 0.713708\n",
      "Epoch 22, Batch 30 training loss: 0.722809\n",
      "Epoch 22, Batch 40 training loss: 0.714723\n",
      "Epoch 22, Batch 50 training loss: 0.721170\n",
      "Epoch 22, Batch 60 training loss: 0.739540\n",
      "Epoch 22, Batch 70 training loss: 0.739767\n",
      "Epoch 22, Batch 80 training loss: 0.739369\n",
      "Epoch 22: Validation Loss: 0.776456\n",
      "Epoch 23, Batch 10 training loss: 0.721848\n",
      "Epoch 23, Batch 20 training loss: 0.743357\n",
      "Epoch 23, Batch 30 training loss: 0.736120\n",
      "Epoch 23, Batch 40 training loss: 0.754023\n",
      "Epoch 23, Batch 50 training loss: 0.742608\n",
      "Epoch 23, Batch 60 training loss: 0.736049\n",
      "Epoch 23, Batch 70 training loss: 0.740225\n",
      "Epoch 23, Batch 80 training loss: 0.732038\n",
      "Epoch 23: Validation Loss: 0.751411\n",
      "Epoch 24, Batch 10 training loss: 0.698684\n",
      "Epoch 24, Batch 20 training loss: 0.686802\n",
      "Epoch 24, Batch 30 training loss: 0.702881\n",
      "Epoch 24, Batch 40 training loss: 0.722244\n",
      "Epoch 24, Batch 50 training loss: 0.725778\n",
      "Epoch 24, Batch 60 training loss: 0.731581\n",
      "Epoch 24, Batch 70 training loss: 0.728827\n",
      "Epoch 24, Batch 80 training loss: 0.739543\n",
      "Epoch 24: Validation Loss: 0.775878\n",
      "Epoch 25, Batch 10 training loss: 0.766228\n",
      "Epoch 25, Batch 20 training loss: 0.747101\n",
      "Epoch 25, Batch 30 training loss: 0.733830\n",
      "Epoch 25, Batch 40 training loss: 0.737462\n",
      "Epoch 25, Batch 50 training loss: 0.748253\n",
      "Epoch 25, Batch 60 training loss: 0.736745\n",
      "Epoch 25, Batch 70 training loss: 0.737214\n",
      "Epoch 25, Batch 80 training loss: 0.737730\n",
      "Epoch 25: Validation Loss: 0.772364\n",
      "Epoch 26, Batch 10 training loss: 0.793833\n",
      "Epoch 26, Batch 20 training loss: 0.770802\n",
      "Epoch 26, Batch 30 training loss: 0.756731\n",
      "Epoch 26, Batch 40 training loss: 0.763943\n",
      "Epoch 26, Batch 50 training loss: 0.770912\n",
      "Epoch 26, Batch 60 training loss: 0.766769\n",
      "Epoch 26, Batch 70 training loss: 0.758022\n",
      "Epoch 26, Batch 80 training loss: 0.750014\n",
      "Epoch 26: Validation Loss: 0.732549\n",
      "Epoch 27, Batch 10 training loss: 0.741651\n",
      "Epoch 27, Batch 20 training loss: 0.718083\n",
      "Epoch 27, Batch 30 training loss: 0.711601\n",
      "Epoch 27, Batch 40 training loss: 0.711194\n",
      "Epoch 27, Batch 50 training loss: 0.724381\n",
      "Epoch 27, Batch 60 training loss: 0.730031\n",
      "Epoch 27, Batch 70 training loss: 0.729031\n",
      "Epoch 27, Batch 80 training loss: 0.730887\n",
      "Epoch 27: Validation Loss: 0.758060\n",
      "Epoch 28, Batch 10 training loss: 0.725237\n",
      "Epoch 28, Batch 20 training loss: 0.715238\n",
      "Epoch 28, Batch 30 training loss: 0.721842\n",
      "Epoch 28, Batch 40 training loss: 0.721081\n",
      "Epoch 28, Batch 50 training loss: 0.725399\n",
      "Epoch 28, Batch 60 training loss: 0.725046\n",
      "Epoch 28, Batch 70 training loss: 0.727486\n",
      "Epoch 28, Batch 80 training loss: 0.739568\n",
      "Epoch 28: Validation Loss: 0.771553\n",
      "Epoch 29, Batch 10 training loss: 0.732159\n",
      "Epoch 29, Batch 20 training loss: 0.716137\n",
      "Epoch 29, Batch 30 training loss: 0.737380\n",
      "Epoch 29, Batch 40 training loss: 0.740634\n",
      "Epoch 29, Batch 50 training loss: 0.741578\n",
      "Epoch 29, Batch 60 training loss: 0.742180\n",
      "Epoch 29, Batch 70 training loss: 0.738397\n",
      "Epoch 29, Batch 80 training loss: 0.737176\n",
      "Epoch 29: Validation Loss: 0.780979\n",
      "Epoch 30, Batch 10 training loss: 0.796504\n",
      "Epoch 30, Batch 20 training loss: 0.791313\n",
      "Epoch 30, Batch 30 training loss: 0.782505\n",
      "Epoch 30, Batch 40 training loss: 0.765182\n",
      "Epoch 30, Batch 50 training loss: 0.755571\n",
      "Epoch 30, Batch 60 training loss: 0.752447\n",
      "Epoch 30, Batch 70 training loss: 0.751008\n",
      "Epoch 30, Batch 80 training loss: 0.748404\n",
      "Epoch 30: Validation Loss: 0.777824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(30, train_loader,valid_loader, model, optimizer,scheduler, criterion, use_cuda=True, save_path='model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the performance on validation data using the image only model. Class 3 has a high score while class 1 is no better than random guess even with the weighting over class 1 and 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of Melanoma: 31% (23/74)\n",
      "Test Accuracy of seborrheic: 61% (33/54)\n",
      "Test Accuracy of nevus: 86% (234/272)\n",
      "\n",
      "Test Accuracy (Overall): 72% (290/400)\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model.pt'))\n",
    "class_correct = list(0. for i in range(3))\n",
    "class_total = list(0. for i in range(3))\n",
    "classes={0:'Melanoma',1:'seborrheic',2:'nevus'}\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(valid_loader):\n",
    "        img = data['image'].float()\n",
    "        #tab_data = data['tab_data'][:,age0_sex1].float()\n",
    "        target = data['target'].long()\n",
    "        batch_size = len(target)\n",
    "        if use_cuda:\n",
    "            img,target = img.cuda(),target.cuda()\n",
    "\n",
    "        output = torch.squeeze(model(img))\n",
    "        loss = criterion(output,target)\n",
    "\n",
    "        _, pred = torch.max(output,1)\n",
    "        correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "        correct = np.squeeze(correct_tensor.numpy()) if not use_cuda else np.squeeze(correct_tensor.cpu().numpy())\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            label = target.data[i]\n",
    "            class_correct[label] += correct[i].item()\n",
    "            class_total[label] +=1\n",
    "\n",
    "for i in range(3):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (100. * np.sum(class_correct) / np.sum(class_total),\n",
    "np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the training for the image and tabular combined model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 10 training loss: 0.762827\n",
      "Epoch 1, Batch 20 training loss: 0.821468\n",
      "Epoch 1, Batch 30 training loss: 0.814042\n",
      "Epoch 1, Batch 40 training loss: 0.820225\n",
      "Epoch 1, Batch 50 training loss: 0.830576\n",
      "Epoch 1, Batch 60 training loss: 0.838275\n",
      "Epoch 1, Batch 70 training loss: 0.835455\n",
      "Epoch 1: Validation Loss: 0.944135\n",
      "Epoch 2, Batch 10 training loss: 0.835027\n",
      "Epoch 2, Batch 20 training loss: 0.861178\n",
      "Epoch 2, Batch 30 training loss: 0.848038\n",
      "Epoch 2, Batch 40 training loss: 0.832284\n",
      "Epoch 2, Batch 50 training loss: 0.827601\n",
      "Epoch 2, Batch 60 training loss: 0.826626\n",
      "Epoch 2, Batch 70 training loss: 0.810804\n",
      "Epoch 2: Validation Loss: 0.876420\n",
      "Epoch     2: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 3, Batch 10 training loss: 0.743822\n",
      "Epoch 3, Batch 20 training loss: 0.744640\n",
      "Epoch 3, Batch 30 training loss: 0.706057\n",
      "Epoch 3, Batch 40 training loss: 0.695929\n",
      "Epoch 3, Batch 50 training loss: 0.701045\n",
      "Epoch 3, Batch 60 training loss: 0.704566\n",
      "Epoch 3, Batch 70 training loss: 0.707207\n",
      "Epoch 3: Validation Loss: 0.785171\n",
      "Epoch     3: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 4, Batch 10 training loss: 0.645223\n",
      "Epoch 4, Batch 20 training loss: 0.666144\n",
      "Epoch 4, Batch 30 training loss: 0.697178\n",
      "Epoch 4, Batch 40 training loss: 0.704785\n",
      "Epoch 4, Batch 50 training loss: 0.703651\n",
      "Epoch 4, Batch 60 training loss: 0.700367\n",
      "Epoch 4, Batch 70 training loss: 0.696948\n",
      "Epoch 4: Validation Loss: 0.809589\n",
      "Epoch     4: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch 5, Batch 10 training loss: 0.704649\n",
      "Epoch 5, Batch 20 training loss: 0.700593\n",
      "Epoch 5, Batch 30 training loss: 0.672290\n",
      "Epoch 5, Batch 40 training loss: 0.675858\n",
      "Epoch 5, Batch 50 training loss: 0.680780\n",
      "Epoch 5, Batch 60 training loss: 0.680762\n",
      "Epoch 5, Batch 70 training loss: 0.687422\n",
      "Epoch 5: Validation Loss: 0.811497\n",
      "Epoch     5: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch 6, Batch 10 training loss: 0.692510\n",
      "Epoch 6, Batch 20 training loss: 0.690237\n",
      "Epoch 6, Batch 30 training loss: 0.691626\n",
      "Epoch 6, Batch 40 training loss: 0.690313\n",
      "Epoch 6, Batch 50 training loss: 0.699391\n",
      "Epoch 6, Batch 60 training loss: 0.699429\n",
      "Epoch 6, Batch 70 training loss: 0.693960\n",
      "Epoch 6: Validation Loss: 0.814546\n",
      "Epoch     6: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch 7, Batch 10 training loss: 0.792907\n",
      "Epoch 7, Batch 20 training loss: 0.727501\n",
      "Epoch 7, Batch 30 training loss: 0.721704\n",
      "Epoch 7, Batch 40 training loss: 0.701515\n",
      "Epoch 7, Batch 50 training loss: 0.688531\n",
      "Epoch 7, Batch 60 training loss: 0.697420\n",
      "Epoch 7, Batch 70 training loss: 0.701051\n",
      "Epoch 7: Validation Loss: 0.812774\n",
      "Epoch 8, Batch 10 training loss: 0.733917\n",
      "Epoch 8, Batch 20 training loss: 0.722931\n",
      "Epoch 8, Batch 30 training loss: 0.723120\n",
      "Epoch 8, Batch 40 training loss: 0.706918\n",
      "Epoch 8, Batch 50 training loss: 0.707272\n",
      "Epoch 8, Batch 60 training loss: 0.703931\n",
      "Epoch 8, Batch 70 training loss: 0.706312\n",
      "Epoch 8: Validation Loss: 0.799449\n",
      "Epoch 9, Batch 10 training loss: 0.630104\n",
      "Epoch 9, Batch 20 training loss: 0.677308\n",
      "Epoch 9, Batch 30 training loss: 0.694302\n",
      "Epoch 9, Batch 40 training loss: 0.682860\n",
      "Epoch 9, Batch 50 training loss: 0.688109\n",
      "Epoch 9, Batch 60 training loss: 0.696997\n",
      "Epoch 9, Batch 70 training loss: 0.697657\n",
      "Epoch 9: Validation Loss: 0.824504\n",
      "Epoch 10, Batch 10 training loss: 0.728511\n",
      "Epoch 10, Batch 20 training loss: 0.714225\n",
      "Epoch 10, Batch 30 training loss: 0.734894\n",
      "Epoch 10, Batch 40 training loss: 0.719191\n",
      "Epoch 10, Batch 50 training loss: 0.709283\n",
      "Epoch 10, Batch 60 training loss: 0.713366\n",
      "Epoch 10, Batch 70 training loss: 0.707481\n",
      "Epoch 10: Validation Loss: 0.817651\n",
      "Epoch 11, Batch 10 training loss: 0.655971\n",
      "Epoch 11, Batch 20 training loss: 0.674981\n",
      "Epoch 11, Batch 30 training loss: 0.662361\n",
      "Epoch 11, Batch 40 training loss: 0.684183\n",
      "Epoch 11, Batch 50 training loss: 0.675354\n",
      "Epoch 11, Batch 60 training loss: 0.695120\n",
      "Epoch 11, Batch 70 training loss: 0.706399\n",
      "Epoch 11: Validation Loss: 0.800073\n",
      "Epoch 12, Batch 10 training loss: 0.718384\n",
      "Epoch 12, Batch 20 training loss: 0.725862\n",
      "Epoch 12, Batch 30 training loss: 0.735548\n",
      "Epoch 12, Batch 40 training loss: 0.717444\n",
      "Epoch 12, Batch 50 training loss: 0.704457\n",
      "Epoch 12, Batch 60 training loss: 0.686171\n",
      "Epoch 12, Batch 70 training loss: 0.690572\n",
      "Epoch 12: Validation Loss: 0.805381\n",
      "Epoch 13, Batch 10 training loss: 0.701604\n",
      "Epoch 13, Batch 20 training loss: 0.694240\n",
      "Epoch 13, Batch 30 training loss: 0.707493\n",
      "Epoch 13, Batch 40 training loss: 0.701302\n",
      "Epoch 13, Batch 50 training loss: 0.714427\n",
      "Epoch 13, Batch 60 training loss: 0.704940\n",
      "Epoch 13, Batch 70 training loss: 0.698393\n",
      "Epoch 13: Validation Loss: 0.809064\n",
      "Epoch 14, Batch 10 training loss: 0.679395\n",
      "Epoch 14, Batch 20 training loss: 0.681634\n",
      "Epoch 14, Batch 30 training loss: 0.723794\n",
      "Epoch 14, Batch 40 training loss: 0.715430\n",
      "Epoch 14, Batch 50 training loss: 0.715911\n",
      "Epoch 14, Batch 60 training loss: 0.704150\n",
      "Epoch 14, Batch 70 training loss: 0.698124\n",
      "Epoch 14: Validation Loss: 0.812201\n",
      "Epoch 15, Batch 10 training loss: 0.707894\n",
      "Epoch 15, Batch 20 training loss: 0.693058\n",
      "Epoch 15, Batch 30 training loss: 0.674509\n",
      "Epoch 15, Batch 40 training loss: 0.677863\n",
      "Epoch 15, Batch 50 training loss: 0.692258\n",
      "Epoch 15, Batch 60 training loss: 0.697644\n",
      "Epoch 15, Batch 70 training loss: 0.699942\n",
      "Epoch 15: Validation Loss: 0.820012\n",
      "Epoch 16, Batch 10 training loss: 0.724525\n",
      "Epoch 16, Batch 20 training loss: 0.714782\n",
      "Epoch 16, Batch 30 training loss: 0.700624\n",
      "Epoch 16, Batch 40 training loss: 0.703133\n",
      "Epoch 16, Batch 50 training loss: 0.705495\n",
      "Epoch 16, Batch 60 training loss: 0.706957\n",
      "Epoch 16, Batch 70 training loss: 0.697230\n",
      "Epoch 16: Validation Loss: 0.809082\n",
      "Epoch 17, Batch 10 training loss: 0.701759\n",
      "Epoch 17, Batch 20 training loss: 0.671145\n",
      "Epoch 17, Batch 30 training loss: 0.674737\n",
      "Epoch 17, Batch 40 training loss: 0.678184\n",
      "Epoch 17, Batch 50 training loss: 0.672863\n",
      "Epoch 17, Batch 60 training loss: 0.678773\n",
      "Epoch 17, Batch 70 training loss: 0.685622\n",
      "Epoch 17: Validation Loss: 0.846650\n",
      "Epoch 18, Batch 10 training loss: 0.662495\n",
      "Epoch 18, Batch 20 training loss: 0.673374\n",
      "Epoch 18, Batch 30 training loss: 0.710710\n",
      "Epoch 18, Batch 40 training loss: 0.703833\n",
      "Epoch 18, Batch 50 training loss: 0.708057\n",
      "Epoch 18, Batch 60 training loss: 0.710564\n",
      "Epoch 18, Batch 70 training loss: 0.712520\n",
      "Epoch 18: Validation Loss: 0.796304\n",
      "Epoch 19, Batch 10 training loss: 0.640481\n",
      "Epoch 19, Batch 20 training loss: 0.627348\n",
      "Epoch 19, Batch 30 training loss: 0.659316\n",
      "Epoch 19, Batch 40 training loss: 0.661772\n",
      "Epoch 19, Batch 50 training loss: 0.664917\n",
      "Epoch 19, Batch 60 training loss: 0.678206\n",
      "Epoch 19, Batch 70 training loss: 0.694635\n",
      "Epoch 19: Validation Loss: 0.802638\n",
      "Epoch 20, Batch 10 training loss: 0.631450\n",
      "Epoch 20, Batch 20 training loss: 0.671179\n",
      "Epoch 20, Batch 30 training loss: 0.681130\n",
      "Epoch 20, Batch 40 training loss: 0.693922\n",
      "Epoch 20, Batch 50 training loss: 0.694288\n",
      "Epoch 20, Batch 60 training loss: 0.693239\n",
      "Epoch 20, Batch 70 training loss: 0.692604\n",
      "Epoch 20: Validation Loss: 0.793684\n",
      "Epoch 21, Batch 10 training loss: 0.609577\n",
      "Epoch 21, Batch 20 training loss: 0.676487\n",
      "Epoch 21, Batch 30 training loss: 0.670922\n",
      "Epoch 21, Batch 40 training loss: 0.684731\n",
      "Epoch 21, Batch 50 training loss: 0.681692\n",
      "Epoch 21, Batch 60 training loss: 0.679940\n",
      "Epoch 21, Batch 70 training loss: 0.690053\n",
      "Epoch 21: Validation Loss: 0.761122\n",
      "Epoch 22, Batch 10 training loss: 0.635502\n",
      "Epoch 22, Batch 20 training loss: 0.651172\n",
      "Epoch 22, Batch 30 training loss: 0.675259\n",
      "Epoch 22, Batch 40 training loss: 0.684899\n",
      "Epoch 22, Batch 50 training loss: 0.691856\n",
      "Epoch 22, Batch 60 training loss: 0.695612\n",
      "Epoch 22, Batch 70 training loss: 0.691228\n",
      "Epoch 22: Validation Loss: 0.804042\n",
      "Epoch 23, Batch 10 training loss: 0.701052\n",
      "Epoch 23, Batch 20 training loss: 0.704176\n",
      "Epoch 23, Batch 30 training loss: 0.695618\n",
      "Epoch 23, Batch 40 training loss: 0.714437\n",
      "Epoch 23, Batch 50 training loss: 0.712401\n",
      "Epoch 23, Batch 60 training loss: 0.707443\n",
      "Epoch 23, Batch 70 training loss: 0.700792\n",
      "Epoch 23: Validation Loss: 0.766076\n",
      "Epoch 24, Batch 10 training loss: 0.731831\n",
      "Epoch 24, Batch 20 training loss: 0.710395\n",
      "Epoch 24, Batch 30 training loss: 0.699171\n",
      "Epoch 24, Batch 40 training loss: 0.702788\n",
      "Epoch 24, Batch 50 training loss: 0.703512\n",
      "Epoch 24, Batch 60 training loss: 0.706505\n",
      "Epoch 24, Batch 70 training loss: 0.701111\n",
      "Epoch 24: Validation Loss: 0.798038\n",
      "Epoch 25, Batch 10 training loss: 0.719620\n",
      "Epoch 25, Batch 20 training loss: 0.729382\n",
      "Epoch 25, Batch 30 training loss: 0.696511\n",
      "Epoch 25, Batch 40 training loss: 0.699666\n",
      "Epoch 25, Batch 50 training loss: 0.699602\n",
      "Epoch 25, Batch 60 training loss: 0.692620\n",
      "Epoch 25, Batch 70 training loss: 0.690975\n",
      "Epoch 25: Validation Loss: 0.790963\n",
      "Epoch 26, Batch 10 training loss: 0.672837\n",
      "Epoch 26, Batch 20 training loss: 0.646528\n",
      "Epoch 26, Batch 30 training loss: 0.659060\n",
      "Epoch 26, Batch 40 training loss: 0.664602\n",
      "Epoch 26, Batch 50 training loss: 0.681907\n",
      "Epoch 26, Batch 60 training loss: 0.688555\n",
      "Epoch 26, Batch 70 training loss: 0.695500\n",
      "Epoch 26: Validation Loss: 0.781120\n",
      "Epoch 27, Batch 10 training loss: 0.726446\n",
      "Epoch 27, Batch 20 training loss: 0.708810\n",
      "Epoch 27, Batch 30 training loss: 0.717749\n",
      "Epoch 27, Batch 40 training loss: 0.704097\n",
      "Epoch 27, Batch 50 training loss: 0.705392\n",
      "Epoch 27, Batch 60 training loss: 0.691056\n",
      "Epoch 27, Batch 70 training loss: 0.693338\n",
      "Epoch 27: Validation Loss: 0.819712\n",
      "Epoch 28, Batch 10 training loss: 0.711219\n",
      "Epoch 28, Batch 20 training loss: 0.694626\n",
      "Epoch 28, Batch 30 training loss: 0.685601\n",
      "Epoch 28, Batch 40 training loss: 0.688220\n",
      "Epoch 28, Batch 50 training loss: 0.701609\n",
      "Epoch 28, Batch 60 training loss: 0.681655\n",
      "Epoch 28, Batch 70 training loss: 0.685981\n",
      "Epoch 28: Validation Loss: 0.778356\n",
      "Epoch 29, Batch 10 training loss: 0.642305\n",
      "Epoch 29, Batch 20 training loss: 0.662547\n",
      "Epoch 29, Batch 30 training loss: 0.684203\n",
      "Epoch 29, Batch 40 training loss: 0.687581\n",
      "Epoch 29, Batch 50 training loss: 0.683505\n",
      "Epoch 29, Batch 60 training loss: 0.690605\n",
      "Epoch 29, Batch 70 training loss: 0.695616\n",
      "Epoch 29: Validation Loss: 0.814729\n",
      "Epoch 30, Batch 10 training loss: 0.728178\n",
      "Epoch 30, Batch 20 training loss: 0.725110\n",
      "Epoch 30, Batch 30 training loss: 0.693316\n",
      "Epoch 30, Batch 40 training loss: 0.711076\n",
      "Epoch 30, Batch 50 training loss: 0.704441\n",
      "Epoch 30, Batch 60 training loss: 0.699079\n",
      "Epoch 30, Batch 70 training loss: 0.699162\n",
      "Epoch 30: Validation Loss: 0.820378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model_img_tab(\n",
       "  (tanh): Tanh()\n",
       "  (fc1): Linear(in_features=2, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=16, bias=True)\n",
       "  (fc3): Linear(in_features=2064, out_features=3, bias=True)\n",
       "  (img_cnn): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img_tab(30, train_loader_2,valid_loader_2, model_img_tab, optimizer_img_tab, scheduler_img_tab,criterion_img_tab, use_cuda=True, save_path='model_img_tab.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is assessed using the validation data below. The tabular data seems to have a slightly better performance for class 1, although the results need to be confirmed more testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of Melanoma: 41% (28/68)\n",
      "Test Accuracy of seborrheic: 54% (28/51)\n",
      "Test Accuracy of nevus: 83% (191/230)\n",
      "\n",
      "Test Accuracy (Overall): 70% (247/349)\n"
     ]
    }
   ],
   "source": [
    "model_img_tab.load_state_dict(torch.load('model_img_tab.pt'))\n",
    "class_correct = list(0. for i in range(3))\n",
    "class_total = list(0. for i in range(3))\n",
    "classes={0:'Melanoma',1:'seborrheic',2:'nevus'}\n",
    "\n",
    "model_img_tab.eval()\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(valid_loader_2):\n",
    "        img = data['image'].float()\n",
    "        tab_data = data['tab_data'].float()\n",
    "        target = data['target'].long()\n",
    "        batch_size = len(target)\n",
    "        if use_cuda:\n",
    "            img,tab_data,target = img.cuda(),tab_data.cuda(),target.cuda()\n",
    "\n",
    "        output = torch.squeeze(model_img_tab(img,tab_data))\n",
    "\n",
    "        _, pred = torch.max(output,1)\n",
    "        correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "        correct = np.squeeze(correct_tensor.numpy()) if not use_cuda else np.squeeze(correct_tensor.cpu().numpy())\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            label = target.data[i]\n",
    "            class_correct[label] += correct[i].item()\n",
    "            class_total[label] +=1\n",
    "\n",
    "for i in range(3):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (100. * np.sum(class_correct) / np.sum(class_total),\n",
    "np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
