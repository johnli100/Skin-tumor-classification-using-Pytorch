{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skin Tumor Classification using Image and Tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage\n",
    "from skimage import io,transform\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "The dataset is a combination of skin tumor image data and the sex and (grouped) age. Some sex and age records are missing (noted as \"unknown\"). The meta-data looks like the following as a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>age_approximate</th>\n",
       "      <th>sex</th>\n",
       "      <th>class</th>\n",
       "      <th>melanoma</th>\n",
       "      <th>seborrheic_keratosis</th>\n",
       "      <th>nevus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>ISIC_0010256.jpg</td>\n",
       "      <td>30</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>ISIC_0000164.jpg</td>\n",
       "      <td>60</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>ISIC_0014327.jpg</td>\n",
       "      <td>80</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>ISIC_0012700.jpg</td>\n",
       "      <td>25</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>ISIC_0000326.jpg</td>\n",
       "      <td>20</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>ISIC_0009915.jpg</td>\n",
       "      <td>45</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>ISIC_0013429.jpg</td>\n",
       "      <td>75</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>ISIC_0013969.jpg</td>\n",
       "      <td>80</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>ISIC_0011158.jpg</td>\n",
       "      <td>60</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>ISIC_0014596.jpg</td>\n",
       "      <td>65</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              image_id age_approximate     sex  class  melanoma  \\\n",
       "791   ISIC_0010256.jpg              30  female      2         0   \n",
       "149   ISIC_0000164.jpg              60    male      0         1   \n",
       "1757  ISIC_0014327.jpg              80  female      0         1   \n",
       "1231  ISIC_0012700.jpg              25    male      2         0   \n",
       "273   ISIC_0000326.jpg              20  female      2         0   \n",
       "622   ISIC_0009915.jpg              45    male      2         0   \n",
       "1489  ISIC_0013429.jpg              75  female      0         1   \n",
       "1657  ISIC_0013969.jpg              80  female      0         1   \n",
       "965   ISIC_0011158.jpg              60    male      0         1   \n",
       "1834  ISIC_0014596.jpg              65  female      1         0   \n",
       "\n",
       "      seborrheic_keratosis  nevus  \n",
       "791                      0      1  \n",
       "149                      0      0  \n",
       "1757                     0      0  \n",
       "1231                     0      1  \n",
       "273                      0      1  \n",
       "622                      0      1  \n",
       "1489                     0      0  \n",
       "1657                     0      0  \n",
       "965                      0      0  \n",
       "1834                     1      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data/ISIC-2017_Training_Data_metadata.csv').sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define the dataset for training and validation below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_lesion(Dataset):\n",
    "    def __init__(self,csv_file,img_dir,transform=True,dropna=True):\n",
    "        self.csv_file = csv_file\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.dropna = dropna\n",
    "        if self.dropna:\n",
    "            missing_values =['unknown','']\n",
    "            self.meta_data = pd.read_csv(csv_file,na_values=missing_values).dropna()\n",
    "            self.meta_data['sex']= pd.get_dummies(self.meta_data['sex'])\n",
    "        else:\n",
    "            self.meta_data = pd.read_csv(csv_file)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.meta_data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        img_path = os.path.join(self.img_dir,self.meta_data.iloc[idx,0])\n",
    "        img = io.imread(img_path)\n",
    "        if self.transform:\n",
    "            img = transform.resize(img,(224,224))\n",
    "            transform_tensor = transforms.Compose([transforms.ToTensor(),\n",
    "                                                  transforms.RandomRotation(30),\n",
    "                                                  transforms.RandomVerticalFlip(),\n",
    "                                                  transforms.RandomHorizontalFlip()])\n",
    "            img = transform_tensor(img)\n",
    "        \n",
    "        target = torch.from_numpy(np.array(self.meta_data.iloc[idx,3]).astype(float))\n",
    "        \n",
    "        if self.dropna:\n",
    "            tab_data = torch.from_numpy(np.array(self.meta_data.iloc[idx,1:3]).astype(float))\n",
    "            sample = {'image':img,'tab_data':tab_data,'target':target}\n",
    "        else:\n",
    "            sample = {'image':img,'target':target}\n",
    "                \n",
    "        return sample        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points: 2000; Image size: torch.Size([3, 224, 224]); sample target: 2.0;\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset_lesion(csv_file='data/ISIC-2017_Training_Data_metadata.csv',\n",
    "                         img_dir='data/ISIC-2017_Training_Data',dropna=False)\n",
    "rand1 = np.random.randint(len(dataset))\n",
    "sample_image,sample_target =dataset[rand1]['image'],dataset[rand1]['target']\n",
    "print(f'Number of data points: {len(dataset)}; Image size: {sample_image.shape}; sample target: {sample_target};')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training/validation data split is 80%/20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_data = int(len(dataset)*0.8)\n",
    "train_data,valid_data=torch.utils.data.random_split(dataset, [num_train_data,len(dataset)-num_train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(train_data,shuffle=True,batch_size=20)\n",
    "valid_loader=DataLoader(valid_data,shuffle=True,batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 3, 224, 224])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "di=iter(train_loader)\n",
    "di.next()['image'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataset with both image and tabular data (sex and age group) below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2 = dataset_lesion(csv_file='data/ISIC-2017_Training_Data_metadata.csv'\n",
    "                                 ,img_dir='data/ISIC-2017_Training_Data')\n",
    "num_train_data_2 = int(len(dataset_2)*0.8)\n",
    "train_data_2,valid_data_2=torch.utils.data.random_split(dataset_2, [num_train_data_2,len(dataset_2)-num_train_data_2])\n",
    "\n",
    "train_loader_2=DataLoader(train_data_2,shuffle=True,batch_size=20)\n",
    "valid_loader_2=DataLoader(valid_data_2,shuffle=True,batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 3, 224, 224])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "di_2=iter(train_loader_2)\n",
    "di_2.next()['image'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "A transfer learning approach is taken by using pre-trained model ResNet_50 replacing the final fully connected layer with customized fully connected layer with three outputs. The loss function is defined as multi-class cross-entropy loss with logits and Adam as the optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True if torch.cuda.is_available() else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet50(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad=False\n",
    "\n",
    "model.fc=torch.nn.Linear(in_features=2048, out_features=3,bias=True)\n",
    "\n",
    "if use_cuda:\n",
    "    model.cuda() \n",
    "    \n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_img_tab(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(model_img_tab, self).__init__()\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "        self.fc1 = torch.nn.Linear(2,64)\n",
    "        self.fc2 = torch.nn.Linear(64,16)\n",
    "        # image features of 2048 + 16 tabular features \n",
    "        self.fc3 = torch.nn.Linear(2064, 3,bias=True)\n",
    "        \n",
    "        resnet50 = torchvision.models.resnet50(pretrained=True)\n",
    "        self.img_cnn = torch.nn.Sequential(*list(resnet50.children())[:-1])\n",
    "        for param in self.img_cnn.parameters():\n",
    "            param.requires_grad=False\n",
    "                \n",
    "    def forward(self,img,tab):\n",
    "        tab = self.tanh(self.fc1(tab))\n",
    "        tab = self.fc2(tab)\n",
    "        img = torch.squeeze(self.img_cnn(img))\n",
    "        out = self.fc3(torch.cat((img,tab),dim=1))        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_img_tab = model_img_tab()\n",
    "\n",
    "if use_cuda:\n",
    "    model_img_tab.cuda() \n",
    "    \n",
    "criterion_img_tab = torch.nn.CrossEntropyLoss()\n",
    "optimizer_img_tab = torch.optim.Adam(model_img_tab.parameters(), lr=0.0003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation\n",
    "The training function is defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs, train_loader,valid_loader, model, optimizer, criterion, use_cuda, save_path):\n",
    "    for e in range(1,n_epochs+1):\n",
    "        train_loss = 0\n",
    "        valid_loss = 0\n",
    "        \n",
    "        model.train()\n",
    "        for i, data in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            img = data['image'].float()\n",
    "            #tab_data = data['tab_data'][:,age0_sex1].float()\n",
    "            target = data['target'].long()\n",
    "            if use_cuda:\n",
    "                img,target = img.cuda(),target.cuda()\n",
    "\n",
    "            pred = torch.squeeze(model(img))\n",
    "            loss = criterion(pred,target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss = train_loss + ((1 / (i + 1)) * (loss.item() - train_loss))\n",
    "\n",
    "            if i % 10 == 9:    # print training loss every specified number of mini-batches\n",
    "                print('Epoch %d, Batch %d training loss: %.6f' % (e, i + 1, train_loss))\n",
    "\n",
    "        model.eval()\n",
    "        for i, data in enumerate(valid_loader):\n",
    "            img = data['image'].float()\n",
    "            #tab_data = data['tab_data'][:,age0_sex1].float()\n",
    "            target = data['target'].long()\n",
    "            if use_cuda:\n",
    "                img,target = img.cuda(),target.cuda()\n",
    "\n",
    "            pred = torch.squeeze(model(img))\n",
    "            loss = criterion(pred,target)\n",
    "            valid_loss = valid_loss + ((1 / (i + 1)) * (loss.item() - valid_loss))\n",
    "\n",
    "            # print training/validation statistics \n",
    "        print('Epoch {}: Validation Loss: {:.6f}'.format(e,valid_loss))\n",
    "\n",
    "        torch.save(model.state_dict(),save_path)\n",
    "        \n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_img_tab(n_epochs, train_loader,valid_loader, model, optimizer, criterion, use_cuda, save_path):\n",
    "    for e in range(1,n_epochs+1):\n",
    "        train_loss = 0\n",
    "        valid_loss = 0\n",
    "        \n",
    "        model.train()\n",
    "        for i, data in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            img = data['image'].float()\n",
    "            tab = data['tab_data'].float()\n",
    "            target = data['target'].long()\n",
    "            if use_cuda:\n",
    "                img,tab,target = img.cuda(),tab.cuda(),target.cuda()\n",
    "\n",
    "            pred = torch.squeeze(model(img,tab))\n",
    "            loss = criterion(pred,target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss = train_loss + ((1 / (i + 1)) * (loss.item() - train_loss))\n",
    "\n",
    "            if i % 10 == 9:    # print training loss every specified number of mini-batches\n",
    "                print('Epoch %d, Batch %d training loss: %.6f' % (e, i + 1, train_loss))\n",
    "\n",
    "        model.eval()\n",
    "        for i, data in enumerate(valid_loader):\n",
    "            img = data['image'].float()\n",
    "            tab = data['tab_data'].float()\n",
    "            target = data['target'].long()\n",
    "            if use_cuda:\n",
    "                img,tab,target = img.cuda(),tab.cuda(),target.cuda()\n",
    "\n",
    "            output = torch.squeeze(model(img,tab))\n",
    "            loss = criterion(output,target)\n",
    "            valid_loss = valid_loss + ((1 / (i + 1)) * (loss.item() - valid_loss))\n",
    "            \n",
    "            # print training/validation statistics \n",
    "        print('Epoch {}: Validation Loss: {:.6f}'.format(e,valid_loss))\n",
    "\n",
    "        torch.save(model.state_dict(),save_path)\n",
    "        \n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following shows the training progress with 30 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 10 training loss: 0.941856\n",
      "Epoch 1, Batch 20 training loss: 1.000088\n",
      "Epoch 1, Batch 30 training loss: 0.960905\n",
      "Epoch 1, Batch 40 training loss: 0.904963\n",
      "Epoch 1, Batch 50 training loss: 0.888727\n",
      "Epoch 1, Batch 60 training loss: 0.885349\n",
      "Epoch 1, Batch 70 training loss: 0.861444\n",
      "Epoch 1, Batch 80 training loss: 0.850823\n",
      "Epoch 1: Validation Loss: 0.721411\n",
      "Epoch 2, Batch 10 training loss: 0.658910\n",
      "Epoch 2, Batch 20 training loss: 0.710829\n",
      "Epoch 2, Batch 30 training loss: 0.726320\n",
      "Epoch 2, Batch 40 training loss: 0.742598\n",
      "Epoch 2, Batch 50 training loss: 0.747265\n",
      "Epoch 2, Batch 60 training loss: 0.740146\n",
      "Epoch 2, Batch 70 training loss: 0.745975\n",
      "Epoch 2, Batch 80 training loss: 0.737437\n",
      "Epoch 2: Validation Loss: 0.644828\n",
      "Epoch 3, Batch 10 training loss: 0.705743\n",
      "Epoch 3, Batch 20 training loss: 0.705413\n",
      "Epoch 3, Batch 30 training loss: 0.726209\n",
      "Epoch 3, Batch 40 training loss: 0.708626\n",
      "Epoch 3, Batch 50 training loss: 0.705054\n",
      "Epoch 3, Batch 60 training loss: 0.686080\n",
      "Epoch 3, Batch 70 training loss: 0.703051\n",
      "Epoch 3, Batch 80 training loss: 0.705217\n",
      "Epoch 3: Validation Loss: 0.618012\n",
      "Epoch 4, Batch 10 training loss: 0.711096\n",
      "Epoch 4, Batch 20 training loss: 0.650787\n",
      "Epoch 4, Batch 30 training loss: 0.652990\n",
      "Epoch 4, Batch 40 training loss: 0.668257\n",
      "Epoch 4, Batch 50 training loss: 0.683529\n",
      "Epoch 4, Batch 60 training loss: 0.689075\n",
      "Epoch 4, Batch 70 training loss: 0.685973\n",
      "Epoch 4, Batch 80 training loss: 0.682686\n",
      "Epoch 4: Validation Loss: 0.613711\n",
      "Epoch 5, Batch 10 training loss: 0.716808\n",
      "Epoch 5, Batch 20 training loss: 0.718494\n",
      "Epoch 5, Batch 30 training loss: 0.703804\n",
      "Epoch 5, Batch 40 training loss: 0.685470\n",
      "Epoch 5, Batch 50 training loss: 0.680607\n",
      "Epoch 5, Batch 60 training loss: 0.673612\n",
      "Epoch 5, Batch 70 training loss: 0.679056\n",
      "Epoch 5, Batch 80 training loss: 0.680192\n",
      "Epoch 5: Validation Loss: 0.620162\n",
      "Epoch 6, Batch 10 training loss: 0.715433\n",
      "Epoch 6, Batch 20 training loss: 0.676068\n",
      "Epoch 6, Batch 30 training loss: 0.701792\n",
      "Epoch 6, Batch 40 training loss: 0.685988\n",
      "Epoch 6, Batch 50 training loss: 0.673157\n",
      "Epoch 6, Batch 60 training loss: 0.682411\n",
      "Epoch 6, Batch 70 training loss: 0.680642\n",
      "Epoch 6, Batch 80 training loss: 0.666086\n",
      "Epoch 6: Validation Loss: 0.567584\n",
      "Epoch 7, Batch 10 training loss: 0.650364\n",
      "Epoch 7, Batch 20 training loss: 0.676145\n",
      "Epoch 7, Batch 30 training loss: 0.660420\n",
      "Epoch 7, Batch 40 training loss: 0.651995\n",
      "Epoch 7, Batch 50 training loss: 0.659168\n",
      "Epoch 7, Batch 60 training loss: 0.670187\n",
      "Epoch 7, Batch 70 training loss: 0.669214\n",
      "Epoch 7, Batch 80 training loss: 0.670161\n",
      "Epoch 7: Validation Loss: 0.590709\n",
      "Epoch 8, Batch 10 training loss: 0.638007\n",
      "Epoch 8, Batch 20 training loss: 0.651762\n",
      "Epoch 8, Batch 30 training loss: 0.633057\n",
      "Epoch 8, Batch 40 training loss: 0.646969\n",
      "Epoch 8, Batch 50 training loss: 0.639758\n",
      "Epoch 8, Batch 60 training loss: 0.640383\n",
      "Epoch 8, Batch 70 training loss: 0.638653\n",
      "Epoch 8, Batch 80 training loss: 0.639336\n",
      "Epoch 8: Validation Loss: 0.597773\n",
      "Epoch 9, Batch 10 training loss: 0.635865\n",
      "Epoch 9, Batch 20 training loss: 0.624861\n",
      "Epoch 9, Batch 30 training loss: 0.653729\n",
      "Epoch 9, Batch 40 training loss: 0.652771\n",
      "Epoch 9, Batch 50 training loss: 0.652796\n",
      "Epoch 9, Batch 60 training loss: 0.648903\n",
      "Epoch 9, Batch 70 training loss: 0.639075\n",
      "Epoch 9, Batch 80 training loss: 0.638183\n",
      "Epoch 9: Validation Loss: 0.554985\n",
      "Epoch 10, Batch 10 training loss: 0.559808\n",
      "Epoch 10, Batch 20 training loss: 0.639408\n",
      "Epoch 10, Batch 30 training loss: 0.632067\n",
      "Epoch 10, Batch 40 training loss: 0.622879\n",
      "Epoch 10, Batch 50 training loss: 0.620066\n",
      "Epoch 10, Batch 60 training loss: 0.620308\n",
      "Epoch 10, Batch 70 training loss: 0.630614\n",
      "Epoch 10, Batch 80 training loss: 0.630884\n",
      "Epoch 10: Validation Loss: 0.574134\n",
      "Epoch 11, Batch 10 training loss: 0.576806\n",
      "Epoch 11, Batch 20 training loss: 0.595753\n",
      "Epoch 11, Batch 30 training loss: 0.575992\n",
      "Epoch 11, Batch 40 training loss: 0.595695\n",
      "Epoch 11, Batch 50 training loss: 0.618772\n",
      "Epoch 11, Batch 60 training loss: 0.616135\n",
      "Epoch 11, Batch 70 training loss: 0.619190\n",
      "Epoch 11, Batch 80 training loss: 0.617344\n",
      "Epoch 11: Validation Loss: 0.579092\n",
      "Epoch 12, Batch 10 training loss: 0.634718\n",
      "Epoch 12, Batch 20 training loss: 0.630317\n",
      "Epoch 12, Batch 30 training loss: 0.608694\n",
      "Epoch 12, Batch 40 training loss: 0.616349\n",
      "Epoch 12, Batch 50 training loss: 0.612051\n",
      "Epoch 12, Batch 60 training loss: 0.625680\n",
      "Epoch 12, Batch 70 training loss: 0.633171\n",
      "Epoch 12, Batch 80 training loss: 0.637467\n",
      "Epoch 12: Validation Loss: 0.566691\n",
      "Epoch 13, Batch 10 training loss: 0.592251\n",
      "Epoch 13, Batch 20 training loss: 0.636625\n",
      "Epoch 13, Batch 30 training loss: 0.651030\n",
      "Epoch 13, Batch 40 training loss: 0.640934\n",
      "Epoch 13, Batch 50 training loss: 0.632509\n",
      "Epoch 13, Batch 60 training loss: 0.637701\n",
      "Epoch 13, Batch 70 training loss: 0.630213\n",
      "Epoch 13, Batch 80 training loss: 0.622506\n",
      "Epoch 13: Validation Loss: 0.563630\n",
      "Epoch 14, Batch 10 training loss: 0.541122\n",
      "Epoch 14, Batch 20 training loss: 0.609880\n",
      "Epoch 14, Batch 30 training loss: 0.609560\n",
      "Epoch 14, Batch 40 training loss: 0.606319\n",
      "Epoch 14, Batch 50 training loss: 0.614011\n",
      "Epoch 14, Batch 60 training loss: 0.603547\n",
      "Epoch 14, Batch 70 training loss: 0.600491\n",
      "Epoch 14, Batch 80 training loss: 0.607861\n",
      "Epoch 14: Validation Loss: 0.557949\n",
      "Epoch 15, Batch 10 training loss: 0.593096\n",
      "Epoch 15, Batch 20 training loss: 0.574479\n",
      "Epoch 15, Batch 30 training loss: 0.590485\n",
      "Epoch 15, Batch 40 training loss: 0.584432\n",
      "Epoch 15, Batch 50 training loss: 0.586344\n",
      "Epoch 15, Batch 60 training loss: 0.596745\n",
      "Epoch 15, Batch 70 training loss: 0.598716\n",
      "Epoch 15, Batch 80 training loss: 0.604322\n",
      "Epoch 15: Validation Loss: 0.581992\n",
      "Epoch 16, Batch 10 training loss: 0.634395\n",
      "Epoch 16, Batch 20 training loss: 0.649050\n",
      "Epoch 16, Batch 30 training loss: 0.642661\n",
      "Epoch 16, Batch 40 training loss: 0.619309\n",
      "Epoch 16, Batch 50 training loss: 0.596673\n",
      "Epoch 16, Batch 60 training loss: 0.594440\n",
      "Epoch 16, Batch 70 training loss: 0.595109\n",
      "Epoch 16, Batch 80 training loss: 0.603938\n",
      "Epoch 16: Validation Loss: 0.573643\n",
      "Epoch 17, Batch 10 training loss: 0.642051\n",
      "Epoch 17, Batch 20 training loss: 0.631835\n",
      "Epoch 17, Batch 30 training loss: 0.616960\n",
      "Epoch 17, Batch 40 training loss: 0.619748\n",
      "Epoch 17, Batch 50 training loss: 0.622661\n",
      "Epoch 17, Batch 60 training loss: 0.602323\n",
      "Epoch 17, Batch 70 training loss: 0.621715\n",
      "Epoch 17, Batch 80 training loss: 0.624442\n",
      "Epoch 17: Validation Loss: 0.585353\n",
      "Epoch 18, Batch 10 training loss: 0.671509\n",
      "Epoch 18, Batch 20 training loss: 0.672818\n",
      "Epoch 18, Batch 30 training loss: 0.660101\n",
      "Epoch 18, Batch 40 training loss: 0.647242\n",
      "Epoch 18, Batch 50 training loss: 0.647978\n",
      "Epoch 18, Batch 60 training loss: 0.628802\n",
      "Epoch 18, Batch 70 training loss: 0.626303\n",
      "Epoch 18, Batch 80 training loss: 0.619873\n",
      "Epoch 18: Validation Loss: 0.569818\n",
      "Epoch 19, Batch 10 training loss: 0.578728\n",
      "Epoch 19, Batch 20 training loss: 0.583509\n",
      "Epoch 19, Batch 30 training loss: 0.579005\n",
      "Epoch 19, Batch 40 training loss: 0.601339\n",
      "Epoch 19, Batch 50 training loss: 0.603752\n",
      "Epoch 19, Batch 60 training loss: 0.612873\n",
      "Epoch 19, Batch 70 training loss: 0.622929\n",
      "Epoch 19, Batch 80 training loss: 0.621372\n",
      "Epoch 19: Validation Loss: 0.573030\n",
      "Epoch 20, Batch 10 training loss: 0.715483\n",
      "Epoch 20, Batch 20 training loss: 0.658128\n",
      "Epoch 20, Batch 30 training loss: 0.623067\n",
      "Epoch 20, Batch 40 training loss: 0.617899\n",
      "Epoch 20, Batch 50 training loss: 0.608112\n",
      "Epoch 20, Batch 60 training loss: 0.602990\n",
      "Epoch 20, Batch 70 training loss: 0.615114\n",
      "Epoch 20, Batch 80 training loss: 0.604398\n",
      "Epoch 20: Validation Loss: 0.603734\n",
      "Epoch 21, Batch 10 training loss: 0.642511\n",
      "Epoch 21, Batch 20 training loss: 0.655012\n",
      "Epoch 21, Batch 30 training loss: 0.603933\n",
      "Epoch 21, Batch 40 training loss: 0.591211\n",
      "Epoch 21, Batch 50 training loss: 0.601752\n",
      "Epoch 21, Batch 60 training loss: 0.595020\n",
      "Epoch 21, Batch 70 training loss: 0.606353\n",
      "Epoch 21, Batch 80 training loss: 0.599580\n",
      "Epoch 21: Validation Loss: 0.557329\n",
      "Epoch 22, Batch 10 training loss: 0.530673\n",
      "Epoch 22, Batch 20 training loss: 0.546862\n",
      "Epoch 22, Batch 30 training loss: 0.542312\n",
      "Epoch 22, Batch 40 training loss: 0.550982\n",
      "Epoch 22, Batch 50 training loss: 0.573402\n",
      "Epoch 22, Batch 60 training loss: 0.580922\n",
      "Epoch 22, Batch 70 training loss: 0.583985\n",
      "Epoch 22, Batch 80 training loss: 0.585221\n",
      "Epoch 22: Validation Loss: 0.554497\n",
      "Epoch 23, Batch 10 training loss: 0.586327\n",
      "Epoch 23, Batch 20 training loss: 0.645724\n",
      "Epoch 23, Batch 30 training loss: 0.621554\n",
      "Epoch 23, Batch 40 training loss: 0.626403\n",
      "Epoch 23, Batch 50 training loss: 0.630787\n",
      "Epoch 23, Batch 60 training loss: 0.620945\n",
      "Epoch 23, Batch 70 training loss: 0.606547\n",
      "Epoch 23, Batch 80 training loss: 0.605455\n",
      "Epoch 23: Validation Loss: 0.554866\n",
      "Epoch 24, Batch 10 training loss: 0.628599\n",
      "Epoch 24, Batch 20 training loss: 0.577236\n",
      "Epoch 24, Batch 30 training loss: 0.583821\n",
      "Epoch 24, Batch 40 training loss: 0.590354\n",
      "Epoch 24, Batch 50 training loss: 0.584667\n",
      "Epoch 24, Batch 60 training loss: 0.578507\n",
      "Epoch 24, Batch 70 training loss: 0.583145\n",
      "Epoch 24, Batch 80 training loss: 0.570354\n",
      "Epoch 24: Validation Loss: 0.573619\n",
      "Epoch 25, Batch 10 training loss: 0.567829\n",
      "Epoch 25, Batch 20 training loss: 0.574021\n",
      "Epoch 25, Batch 30 training loss: 0.568774\n",
      "Epoch 25, Batch 40 training loss: 0.578741\n",
      "Epoch 25, Batch 50 training loss: 0.598615\n",
      "Epoch 25, Batch 60 training loss: 0.595563\n",
      "Epoch 25, Batch 70 training loss: 0.600039\n",
      "Epoch 25, Batch 80 training loss: 0.596288\n",
      "Epoch 25: Validation Loss: 0.538509\n",
      "Epoch 26, Batch 10 training loss: 0.606460\n",
      "Epoch 26, Batch 20 training loss: 0.616777\n",
      "Epoch 26, Batch 30 training loss: 0.587730\n",
      "Epoch 26, Batch 40 training loss: 0.598440\n",
      "Epoch 26, Batch 50 training loss: 0.601165\n",
      "Epoch 26, Batch 60 training loss: 0.591881\n",
      "Epoch 26, Batch 70 training loss: 0.598845\n",
      "Epoch 26, Batch 80 training loss: 0.598960\n",
      "Epoch 26: Validation Loss: 0.585346\n",
      "Epoch 27, Batch 10 training loss: 0.567705\n",
      "Epoch 27, Batch 20 training loss: 0.526271\n",
      "Epoch 27, Batch 30 training loss: 0.520809\n",
      "Epoch 27, Batch 40 training loss: 0.536274\n",
      "Epoch 27, Batch 50 training loss: 0.552118\n",
      "Epoch 27, Batch 60 training loss: 0.554453\n",
      "Epoch 27, Batch 70 training loss: 0.575234\n",
      "Epoch 27, Batch 80 training loss: 0.583296\n",
      "Epoch 27: Validation Loss: 0.555369\n",
      "Epoch 28, Batch 10 training loss: 0.548610\n",
      "Epoch 28, Batch 20 training loss: 0.516947\n",
      "Epoch 28, Batch 30 training loss: 0.548037\n",
      "Epoch 28, Batch 40 training loss: 0.560672\n",
      "Epoch 28, Batch 50 training loss: 0.585461\n",
      "Epoch 28, Batch 60 training loss: 0.590518\n",
      "Epoch 28, Batch 70 training loss: 0.593204\n",
      "Epoch 28, Batch 80 training loss: 0.587517\n",
      "Epoch 28: Validation Loss: 0.544338\n",
      "Epoch 29, Batch 10 training loss: 0.619411\n",
      "Epoch 29, Batch 20 training loss: 0.602509\n",
      "Epoch 29, Batch 30 training loss: 0.601575\n",
      "Epoch 29, Batch 40 training loss: 0.588845\n",
      "Epoch 29, Batch 50 training loss: 0.590212\n",
      "Epoch 29, Batch 60 training loss: 0.589635\n",
      "Epoch 29, Batch 70 training loss: 0.586301\n",
      "Epoch 29, Batch 80 training loss: 0.583033\n",
      "Epoch 29: Validation Loss: 0.552125\n",
      "Epoch 30, Batch 10 training loss: 0.550378\n",
      "Epoch 30, Batch 20 training loss: 0.572569\n",
      "Epoch 30, Batch 30 training loss: 0.577291\n",
      "Epoch 30, Batch 40 training loss: 0.586485\n",
      "Epoch 30, Batch 50 training loss: 0.589050\n",
      "Epoch 30, Batch 60 training loss: 0.597888\n",
      "Epoch 30, Batch 70 training loss: 0.592853\n",
      "Epoch 30, Batch 80 training loss: 0.595586\n",
      "Epoch 30: Validation Loss: 0.547611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(30, train_loader,valid_loader, model, optimizer, criterion, use_cuda=True, save_path='model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 10 training loss: 0.939758\n",
      "Epoch 1, Batch 20 training loss: 0.958122\n",
      "Epoch 1, Batch 30 training loss: 0.919335\n",
      "Epoch 1, Batch 40 training loss: 0.921649\n",
      "Epoch 1, Batch 50 training loss: 0.901156\n",
      "Epoch 1, Batch 60 training loss: 0.888318\n",
      "Epoch 1, Batch 70 training loss: 0.860335\n",
      "Epoch 1: Validation Loss: 0.776793\n",
      "Epoch 2, Batch 10 training loss: 0.835327\n",
      "Epoch 2, Batch 20 training loss: 0.813982\n",
      "Epoch 2, Batch 30 training loss: 0.806252\n",
      "Epoch 2, Batch 40 training loss: 0.782952\n",
      "Epoch 2, Batch 50 training loss: 0.797082\n",
      "Epoch 2, Batch 60 training loss: 0.782082\n",
      "Epoch 2, Batch 70 training loss: 0.769545\n",
      "Epoch 2: Validation Loss: 0.704565\n",
      "Epoch 3, Batch 10 training loss: 0.707226\n",
      "Epoch 3, Batch 20 training loss: 0.742417\n",
      "Epoch 3, Batch 30 training loss: 0.737836\n",
      "Epoch 3, Batch 40 training loss: 0.718034\n",
      "Epoch 3, Batch 50 training loss: 0.715483\n",
      "Epoch 3, Batch 60 training loss: 0.714565\n",
      "Epoch 3, Batch 70 training loss: 0.714927\n",
      "Epoch 3: Validation Loss: 0.701403\n",
      "Epoch 4, Batch 10 training loss: 0.698494\n",
      "Epoch 4, Batch 20 training loss: 0.707998\n",
      "Epoch 4, Batch 30 training loss: 0.710299\n"
     ]
    }
   ],
   "source": [
    "train_img_tab(20, train_loader_2,valid_loader_2, model_img_tab, optimizer_img_tab, criterion_img_tab, use_cuda=True, save_path='model_img_tab.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is assessed using the validation data below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of Melanoma: 34% (23/67)\n",
      "Test Accuracy of seborrheic: 37% (19/51)\n",
      "Test Accuracy of nevus: 91% (259/282)\n",
      "\n",
      "Test Accuracy (Overall): 75% (301/400)\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model.pt'))\n",
    "class_correct = list(0. for i in range(3))\n",
    "class_total = list(0. for i in range(3))\n",
    "classes={0:'Melanoma',1:'seborrheic',2:'nevus'}\n",
    "\n",
    "model.eval()\n",
    "for i, data in enumerate(valid_loader):\n",
    "    img = data['image'].float()\n",
    "    #tab_data = data['tab_data'][:,age0_sex1].float()\n",
    "    target = data['target'].long()\n",
    "    batch_size = len(target)\n",
    "    if use_cuda:\n",
    "        img,target = img.cuda(),target.cuda()\n",
    "\n",
    "    output = torch.squeeze(model(img))\n",
    "    loss = criterion(output,target)\n",
    "\n",
    "    _, pred = torch.max(output,1)\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not use_cuda else np.squeeze(correct_tensor.cpu().numpy())\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] +=1\n",
    "\n",
    "for i in range(3):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (100. * np.sum(class_correct) / np.sum(class_total),\n",
    "np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
